{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Комп’ютерний практикум 8. Класифікація рукописних чисел повнозв’язною мережею мережею. Методи оптимізації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.datasets\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)\n",
    "\n",
    "X_train = MNIST_train.train_data\n",
    "y_train = MNIST_train.train_labels\n",
    "\n",
    "X_test = MNIST_test.test_data\n",
    "y_test = MNIST_test.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtype, y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.float()\n",
    "X_test = X_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0, :, :])\n",
    "plt.show()\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([-1, 28 * 28])\n",
    "X_test = X_test.reshape([-1, 28 * 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "mnist_net = MNISTNet(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mnist_net = mnist_net.to(device)\n",
    "\n",
    "# list(mnist_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "test_accuracy_history = []\n",
    "test_loss_history = []\n",
    "validation_loss_history = []\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(50):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    \n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "\n",
    "        X_batch = X_train[batch_indexes].to(device)\n",
    "        y_batch = y_train[batch_indexes].to(device)\n",
    "\n",
    "        preds = mnist_net.forward(X_batch)\n",
    "\n",
    "        loss_value = loss(preds, y_batch)\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_preds = mnist_net.forward(X_test)\n",
    "    test_loss_history.append(loss(test_preds, y_test))\n",
    "    \n",
    "    validation_loss_history.append(loss_value)\n",
    "    \n",
    "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean()\n",
    "    test_accuracy_history.append(accuracy)\n",
    "    print(epoch, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_accuracy_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Завдання.__ Зробіть покращення у нейронній мережі та дайте відповідь на наступні питання:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Побудуйте на одному графіку loss для train і validation. Чи правда, що loss на train і validation падає однаково швидко і виходить на однакове значення, або ж у нас є перенавчання?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss_history, color='g')\n",
    "plt.plot(validation_loss_history, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Чи веде збільшення кількості епох (40 епох -> 200 епох) до поліпшення метрик на валідації?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Чи уповільнює torch.backends.cudnn.deterministic = True навчання на практиці? Якщо так, то наскільки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Спробуйте різні методи градієнтного спуску. Як вибір градієнтного спуску впливає на accuracy? Для впевненості краще проводити один експеримент 3-5 разів на різних random seed: так ви зрозумієте, чи дійсно позначається вплив методу або справа в випадковості."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Реалізуйте функціональність torch.nn.Linear з нуля і звірте з оригіналом!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linL():\n",
    "    def __init__(self, n_inp, n_out, bias=True):\n",
    "        self.n_inp = n_inp \n",
    "        self.n_out = n_out \n",
    "        self.bias = np.ones((self.n_out)) if bias else None \n",
    "        \n",
    "        self.W = np.ones((self.n_inp, self.n_out))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if self.bias is not None:\n",
    "            self.Y = X.dot(self.W) + self.bias\n",
    "        else:\n",
    "            self.Y = X.dot(self.W)\n",
    "        return self.Y\n",
    "    \n",
    "\n",
    "lin_obj = linL(100, 50)\n",
    "\n",
    "X = np.ones((100))\n",
    "Y = lin_obj.forward(X)\n",
    "\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Знайдіть оптимальну кількість епох для навчання, аналізуючи графіки втрат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Нехай у нас буде 1 об'єкт x на вході з двома компонентами. Його ми передамо в повнозв'язний шар з 3-ма нейронами і отримаємо, відповідно, 3 виходи. Після цього напишіть цю ж функціональність за допомогою матричного множення. Та перевірте розрахунок похідної."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[10., 20.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = torch.nn.Linear(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(\n",
    "    [[11., 12.], \n",
    "     [21., 22.], \n",
    "     [31., 32]]\n",
    ")\n",
    "fc.weight.data = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor(\n",
    "    [[31., 32., 33.]]\n",
    ")\n",
    "fc.bias.data = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_out = fc(x)\n",
    "fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_out_summed = fc_out.sum()\n",
    "fc_out_summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_out_summed.backward()\n",
    "weight_grad = fc.weight.grad\n",
    "weight_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_grad = fc.bias.grad\n",
    "bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер зробимо розрахунки які були вище але без fc-шару.<br>Зазначимо, що у \"w\" та \"b\" необхідно розраховувати градієнти (для fc-шара це виходить автоматично):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Спробуйте отримати аналогічні результати використовуючи матричне множення\n",
    "fc_out_alternative = torch.matmul(x, w.T) + b   # x * w^T + b\n",
    "fc_out_alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отримаємо вихід після сумування нашої формули:\n",
    "our_formula = torch.sum(fc_out_alternative) # SUM{x * w^T + b}\n",
    "our_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зробіть backward для нашої формули:\n",
    "our_formula.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fc_out == fc_out_alternative)\n",
    "\n",
    "print('fc_weight_grad:', weight_grad)\n",
    "print('our_weight_grad:', w.grad)\n",
    "\n",
    "print('fc_bias_grad:', bias_grad)\n",
    "print('out_bias_grad:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Зробіть аналогічні розрахунки та натренеруйте модель для датасету CIFAR 10. Напишіть звіт, де вкажіть, що це за датасет, особливості, кількість класів, модель, результат, тощо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.datasets\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_train = torchvision.datasets.CIFAR10('./', download=True, train=True)\n",
    "CIFAR10_test = torchvision.datasets.CIFAR10('./', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| <class 'torch.Tensor'> torch.Size([50000, 32, 32, 3]) | <class 'torch.Tensor'> torch.Size([50000]) |\n",
      "| <class 'torch.Tensor'> torch.Size([10000, 32, 32, 3]) | <class 'torch.Tensor'> torch.Size([10000]) |\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(CIFAR10_train.data)\n",
    "y_train = torch.from_numpy(np.array(CIFAR10_train.targets))\n",
    "\n",
    "X_test = torch.from_numpy(CIFAR10_test.data)\n",
    "y_test = torch.from_numpy(np.array(CIFAR10_test.targets))\n",
    "\n",
    "print('|', type(X_train), X_train.shape, '|', type(y_train), y_train.shape, '|')\n",
    "print('|', type(X_test), X_test.shape, '|', type(y_test), y_test.shape, '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIFAR10_train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdM0lEQVR4nO2da6xcV5Xn/6tet+7DyY1jx3YcY4e0eaQJBDAZWkSIph+TQS0FRqMIRmLyAbVbo0YapJ4PESMNjDQf6NEAQjMjRs4k6vSI4dWAiEaIbjpqNaJHSnNJhzxJCMHENn7Gvu9bj3POmg9VaTnp/V/3+j7qGvb/J1muu1fts3ftc1adqv2vtZa5O4QQv/7UtnsCQojRIGcXIhPk7EJkgpxdiEyQswuRCXJ2ITKhsZHOZnYXgC8AqAP4X+7+mej5u3bt8kOHDhLreiTA9cqGts5+bLzoeJGtWuc81jt/xijl12jufB6hQhwZ2XDR8cLlDYzhPK78nK1HFn/ppRO4cOHl5GDrdnYzqwP4HwB+D8BJAD80s4fd/RnW59Chg5iZ+bukLXxhXpJJFNEMA0tzXf0cfdIjWkb+4cnR47ZgPQZLT63p41XBG4tFY/Fu7tGbVfp114yvRxUcryzJNQCg7KfPCwA0Gum1Kks+Vm0d6wsAZbQewetma1KU0fWdPmd33vm7fJzgaKtxB4AX3P1Fd+8B+AqAuzdwPCHEFrIRZ98P4MRlf58ctgkhrkK2fIPOzI6a2YyZzZw/f36rhxNCEDbi7KcAHLjs75uGba/C3Y+5+xF3P7J79+4NDCeE2AgbcfYfAjhsZjebWQvAhwE8vDnTEkJsNuvejXf3wsw+DuAvMZDeHnT3p1fphKpI71gWRSC7gO3Erm8Xme7uA/BoN570s0gyCjZoB/uaaWKlJtotZmMFa1ULdoprfKyq5MesKqJcBC8sslXB7nkVXMbMVhR8B79WiyQIbqoCxaPf4+e62WynhwrGajav/D69IZ3d3b8D4DsbOYYQYjToF3RCZIKcXYhMkLMLkQlydiEyQc4uRCZsaDf+SimKHi69/FLSZoGctNJZIn2iQAwun9TrrXX1K8q0fNKo88CaquAyX7e7QG3NJj81jUYwfyLX9Htcaopec3t8itoWFxeprSg6yfZmi69Vs8ltRcGDQqzG+03uuDbZPnvpIu0TqI2IIhX7/RVu6/J+1167K9lekuttYFtOj9NLrzugO7sQ2SBnFyIT5OxCZIKcXYhMkLMLkQkj3Y2vqh5WFtO78Y3GJO1XrHST7WZRMAN/abVg17dW8V1fX7qUbO+u8F3pzgK31YJd5Po111Fb64Y91GatdFBFrR4FDQW78U2+I1yf4OtfFul+3ksrKwBgZaCEzPFcCJ3F9PUBANV0Oqx6bCx4zSSVFQA0WlydqCbHqA0eXFfVfLK9aPAd/HYjrfI0gvOsO7sQmSBnFyIT5OxCZIKcXYhMkLMLkQlydiEyYaTSW7Nex67rrknaul0uhUy10oEfdU8HAwBAUfKAgKLDA1Dmz/2TBLn/SG/2bLK9TXPkAUtnzvHjdblM0tjBpbdy+RC17di9L9nebnPJKKrS0p/n0uHCxfR6AEBvaTbZPn/uZdoHLT6PlbkL3HY+LYkCQMfT105F8r4BQLvFpbfr9h6gtj0Hb6a2os/Xsayn57Lr0GHap0GCuSIZVXd2ITJBzi5EJsjZhcgEObsQmSBnFyIT5OxCZMKGpDczOw5gAUAJoHD3I9HzK6/Q66YlsaIflP7pp/vMXfoF7dMO8ohdPHWS2i798gS1XTeZljvGr9sRzCPICVbjUWONPo+SWjnBpcOVM88l2+tBnrx6UO6o3+MRZWWfR8Q5SYbXDEoaeYcbmxUfa+J6HjF5/kJa8jr+fDr6EgB2jvNoM7/4M2qbe+GH1Lbc5ef65ne9Nz3WgUO0T4fkNoxKUG2Gzv7b7s5FUCHEVYE+xguRCRt1dgfwV2b2IzM7uhkTEkJsDRv9GH+nu58ysxsAfM/MfuLu37/8CcM3gaMAcGA/z7AihNhaNnRnd/dTw//PAfgWgDsSzznm7kfc/cj116cT9gshtp51O7uZTZrZjlceA/h9AE9t1sSEEJvLRj7G7wHwrWGUTQPA/3H374Y93FGVaUnJAklm5dLpZPv8mRdpn6rFk//Nv8Tlk4kaly4mJ9ISz3KXJ1Gst4JovnEuGdVqvMRTrcFlNLaM/R6X66JkiFElJKtza72dfm1lUD7p5RO/pLayChJE7tlLbVOt9Dx288Phxmv5+k5Pc5l1YYHLrDcGUYw3vO5gsr3b5bJnoyDXXMUjMNft7O7+IoC3rbe/EGK0SHoTIhPk7EJkgpxdiEyQswuRCXJ2ITJhpAknHUBZpsWhyrkk0y/SkUuNiiecvHQmSBzZ5XXDpq5PJ8QEgNpEur2zFERkTU9Tm9W5PFgFopd7IHlRA39fL4LotahmXnuMz7/RTEuH/ZLLSeNc8UJnmSdsnDv5ArWdv5SONlsxvoY7b+Mi0+5b3sltxtfq/M+fpraup3XAVpvLfNV8+tr3QMLWnV2ITJCzC5EJcnYhMkHOLkQmyNmFyISR7sbX62OYujZdIseNB2P0yU7s6aefoH2WThynttYY3/kvK14mqddN96sb30auCp57rOpxm4U544Jt61p6l7k1NU67NBEoBhXfta6ISgIAXqbXarLJg3+WJvjaL108Q231kqsJ506tJNtfOM1VgTe/YT+1XV/xoCdr76a2Zo1vk7O1al+TLuUFAL1eOuDFAvVEd3YhMkHOLkQmyNmFyAQ5uxCZIGcXIhPk7EJkwmgDYbxCQQIh5peCQIeltGzx6FNcjpl76SK1HZjmARz9zjy17R1L5xFbWuEBOZ2L/HjtMb78E0FUSHuM22pj7WS79/lYjTaX3up1LpXNzc9RW4sENtWv5fLaxCSf48IEP2fFMpfems20dLgUBC/NXbhEbctnnqQ2L/j8g+pVmNxFcugFUS3lCvGXoPyT7uxCZIKcXYhMkLMLkQlydiEyQc4uRCbI2YXIhFWlNzN7EMAfADjn7m8Ztu0E8FUAhwAcB3CPu3O94hW8QtVNSwatBpcM9uxNR/8sGpeMvvUEl7wOX8cjwG45yyPR3lyk5Z9Ol+sq50+eo7ZrJnmJp53X8DlO7+C2HeNpqakxztfXmlymbDZ5Mc6FOX7Ka0hHZRV7+Tlr1Pna143Pf3GFR0y2p9Lj7Xsdf13Hf3qW2qbb3GXG2oEkuvsQt7XSxyxW+Hkpe2k/8iCX41ru7H8G4K7XtN0H4BF3PwzgkeHfQoirmFWdfVhv/bVvMXcDeGj4+CEAH9zkeQkhNpn1fmff4+6vlFY9g0FFVyHEVcyGN+jc3cErBcPMjprZjJnNXHh5dqPDCSHWyXqd/ayZ7QOA4f90F8rdj7n7EXc/sut6vjkjhNha1uvsDwO4d/j4XgDf3pzpCCG2irVIb18G8D4Au8zsJIBPAfgMgK+Z2ccA/ALAPWsazUugn/4oXwZJA+sk+eJbb7uF9rlwkctCJ4+foLaZIFruuYvpMkOdLpd+mg0ur+1opeUpABivpxMlAsBkiyeBvGYsXUpoklcSQo2UagKAosvLaBXdDrVZehrYu4eflxt2piP2AGDpLJcwl0u+ju/80L9Mtr/ndbfSPl/97/+N2v720ZPUtndvOioSAG6/iduMXPsGfl0V5DYdVH9a3dnd/SPE9Dur9RVCXD3oF3RCZIKcXYhMkLMLkQlydiEyQc4uRCaMNOEkUAG1dMLJWsGlt1qZjoZ692+9mfZ51z97C7Xdf//Xqe273/0BtU0209Fm/WDuL1/iySiLHUEyR+eyizuXvNrNtEw5doFoYQAaNS5d9QJZq9vj9dLq5DbyfBBV2CKRcgCAxQvUdNu7fpPabrzlcLJ9535eR+3GW99Kbf/vL/+O2s4HiUff1OfyZtVPy6y9oE5gWbCx+Brqzi5EJsjZhcgEObsQmSBnFyIT5OxCZIKcXYhMGKn01un28fyL6SiqyXFey2uC2Bo8+AtT41zquCGIq59o8Xl4mZavLHjL7JZcjqlaPBRt564bqe1ikOhxbjk9XiNQtSZJwsMBfJGL6PKxdL/5Lo/LKgIpb/fO3dR223vfT20dol49/cxPaJ8bDh2itl2/wZNRLlzi8uDZ+QVq20vkzV6PS2/eT0uzQXk43dmFyAU5uxCZIGcXIhPk7EJkgpxdiEwY6W78pdlFfPPb6UCCqUm+Cz597VSyfbzNgzv27eLlfS5e4LvZ9WBrfXExHYCyUizRPvsP7KW21x9+E7XtuJbnLNsf7LjOXUzvCL98nu8iN4P3fAvy61VzfIe5UUsfczZQEur8EsA7338ntc1WXDH4+sPpwKb5FX7OmmMT1HaJxzxhnosJmHmG5z08t5Re46W5OdpnilynS+QaBXRnFyIb5OxCZIKcXYhMkLMLkQlydiEyQc4uRCaspfzTgwD+AMA5d3/LsO3TAP4QwPnh0z7p7t9Z7VgOQ6dMyyRLL/NyR2fOL6bnVuMa1FP109R28rmXqK3DIicA2FiVbJ+cSkuDAPCbt72N2sav4YEw8wvp1wwA7QbXqA687kCyfd+B/bRPEQRcVB2uJz372I+prWnpczMxwWWy17/xILX97j//bWr7wcyT1DbfS8/Dg0u/3+NyY1mlrwEAmF3kQU/nLnKp7+Li8fRYfa7zjSEtOy93+blcy539zwDclWj/vLvfPvy3qqMLIbaXVZ3d3b8PgFc7FEL8SrCR7+wfN7MnzOxBM+M/9xJCXBWs19m/COAWALcDOA3gs+yJZnbUzGbMbGZ5hf+UTwixtazL2d39rLuX7l4BuB/AHcFzj7n7EXc/MjHO628LIbaWdTm7mV1eTuNDAJ7anOkIIbaKtUhvXwbwPgC7zOwkgE8BeJ+Z3Q7AARwH8EdrGcwMaI6lh6w3gvcdkljLifwAAHVLl0ECgCJ4jyuMSyvdxbQ8eNsb0iWGAKA5xj/NdANZqwpK/3SLIKEcK//T4Ke66AdyTcXlzdZEuhwWAHRm09FtBw/eRPv8639zD7W98Y2HqK0e5ND767+dSbbPL/BrwJ3b9uzbSW17b+S5DVuBXNrpps9Z0eR5FOHpPlYLynzxow2P6f6RRPMDq/UTQlxd6Bd0QmSCnF2ITJCzC5EJcnYhMkHOLkQmjDThpANwIuWUJZe8KhJp1Gxwea1hXIKo1bmcVG/yfhONdHRbc4zLKkXJI6g8qNVTCxJfGknmCAA9IqOVQWmleo1HojWCeUwF0X6nz51Ptludn7MXXkqXBgOAU0TKA4Bd01wOu+H6tO3cmeO0j5PSVQBAKoABACYmuDvd/pY38GP20r8sPflLHrk5O5+OsKvXg+ueWoQQv1bI2YXIBDm7EJkgZxciE+TsQmSCnF2ITBit9OaOXi+dRK8KoqsGYfP/lLLk0V9Vg9vqTS6tTO/kkUsTE+kEkcsrPNHgRI/LU7VIQiPrtBoNEt1Wga+vBTKlB/eD6Jj1sXTE1nKHS5GP/cPz1NZt8HPWCiIm22Q9en3+mvsFl4FrwTzKLpcVf/bTn1PbGw/vS7YfOphuB4DzF9PXRzOIlNOdXYhMkLMLkQlydiEyQc4uRCbI2YXIhJHuxg9I74JWVVByhwTJLK/wklGtJn9p7Ykgy23Fd/Gnp9M79ZeCUk3Rrnq9znd2ox3ySIVgtkaL7xRHATlMCQGA2bk5alsp2Pnk52V5gacaL8d5vrs+y7sHYMnSx6wFwT9e8vVAj98f+3U+x588x4N8fv7zk8n2WqAyFFXatrzM11B3diEyQc4uRCbI2YXIBDm7EJkgZxciE+TsQmTCWso/HQDw5wD2YJBG7pi7f8HMdgL4KoBDGJSAusfdeaIwDPLP9XokR1ogJzGZZHx8IujDpauqy/OxBSoUDVxpBaWVukHlWhYsAgC1SJZbRw66fiApNgIZqiz5Wl2anaW2ycl00NBiIJeiz23tnTzPnAfrYSQnmxmXeqOcfAikyG6xQG1VEFyz0k3P0YNSZKWn518GOQ/XcmcvAPyJu98K4N0A/tjMbgVwH4BH3P0wgEeGfwshrlJWdXZ3P+3ujw0fLwB4FsB+AHcDeGj4tIcAfHCrJimE2DhX9J3dzA4BeDuARwHscfdXct2eweBjvhDiKmXNzm5mUwC+AeAT7j5/uc0Hv7dMfts1s6NmNmNmMytBiWIhxNayJmc3syYGjv4ld//msPmsme0b2vcBOJfq6+7H3P2Iux8Zb/NiCkKIrWVVZ7dBRMYDAJ51989dZnoYwL3Dx/cC+PbmT08IsVmsJertPQA+CuBJM3t82PZJAJ8B8DUz+xiAXwC4Z7UDuQO9floC6nZ5dFizmY7YqgKdrN3mslazyaOTzIIINiJrdZZ4Drqa8SVuXZOWpwCgDCQeI2sIACAlscpAeoukyN4yl8PGgjXec2M6f9qZEy/RPv0FPo+909dRWxGsVY2bKBZIXqwUGQD0+5Gcx68DFnUYjVWQscogYm9VZ3f3H4DFpQK/s1p/IcTVgX5BJ0QmyNmFyAQ5uxCZIGcXIhPk7EJkwmjLP8FpmadWK5DKWFRZENm2vLxEbZF01S24zTppebDe5lJehyZeBCxIDtgMIuKi92gW9RQlsGTSJgAs9nhSyWZwzioy3PjUJO1T4wrmKkkxua1GEo9Gr7kbSJFRdGYkr0XrzyS26HUVJHo0XAtqEUL8WiFnFyIT5OxCZIKcXYhMkLMLkQlydiEyYaTSm8Fo0kbWDgB1Ir1VQbQTolpp6TwbAICpILqqTySSi5d4ns3JCZ4Us4qi5YJElZMTXL5icmSUiJBbgKJISzwA0Ajq6ZXkdE7s4HNvBrXNIumqRSL9Bh3T57pPIhg3QjDFEFbzr94IEoGSqLdonXRnFyIT5OxCZIKcXYhMkLMLkQlydiEyYaS78TBelqkKcqQVRbpPrc7fq6KdYo926oMyPVPj6ZxxUbBLI9hRbUYlnoy/tijYgQVqlD2e4y/K5VdEgTxRGSrSrxluWXNbtMscEak86xkrOl4RBFj1g3Usia0Igm68vPLgGd3ZhcgEObsQmSBnFyIT5OxCZIKcXYhMkLMLkQmrSm9mdgDAn2NQktkBHHP3L5jZpwH8IYDzw6d+0t2/s8qx0CSS2EoQ+FFVadmoiUDWCvLTeRBwEXSDeTp44vrpKdonykvGAiCAOFAjlFfIC/DghZFYEQDAvptuoralIJBnmeRIa0VyabAeUZRJEQT5NCx9zCjPXCS9NVg+RMRSZK0WyKVkPAvOWVkEJ42wFp29APAn7v6Yme0A8CMz+97Q9nl3/69XPKoQYuSspdbbaQCnh48XzOxZAPu3emJCiM3lir6zm9khAG8H8Oiw6eNm9oSZPWhmPBBcCLHtrNnZzWwKwDcAfMLd5wF8EcAtAG7H4M7/WdLvqJnNmNlM9L1cCLG1rMnZzayJgaN/yd2/CQDuftbdS3evANwP4I5UX3c/5u5H3P3I+Hh7s+YthLhCVnV2G2xNPgDgWXf/3GXt+y572ocAPLX50xNCbBZr2Y1/D4CPAnjSzB4ftn0SwEfM7HYM5LjjAP5o1SO5B+VzuJTApJBOh38tKIPcaYFyhWaL5zNjEWxR1JgHefLKMope43ISKxc0tCZbazUua/V6QcRhh9saY+koQAAoVy6mj+f8eL0VLuW1AxkqKr9VkHJe0XpEVCTaDACC0xnmk3Ny7ROlFwDQaJL1iGRDfrjhgO4/QDr2MNTUhRBXF/oFnRCZIGcXIhPk7EJkgpxdiEyQswuRCSNNOOngEVtRIj8m1/VIZBUAdDs8qmms1eL9Vnhixj6RqJpBJFTfo2SUvF8kr0VJIGtEeqlHpZUCWWtpha9xPYjkajbHku2d7iLtMzU9TW3j47yM1uw8P2anl16rViCxjo2l5w7E56wWJgLl57NeT8+lqvjxGqQPO/+A7uxCZIOcXYhMkLMLkQlydiEyQc4uRCbI2YXIhJFKb2VZYnZ29or7MbkuStg4OcGTQDabXHaJo9TSNhZZBQC1epD4ch012wbjcemNvn/3g0i5YB5joZQTzIN0Wwxq6bWbPHqtNb2P2nz5l9RWLL+cbO8Fte86gWzbCmTbKBgxSg+5Hjm60bjy2ne6swuRCXJ2ITJBzi5EJsjZhcgEObsQmSBnFyITRiq9VVWFxeV0kshWg8thTP2pIgWqxWW5eoMLIZF8Mjs3l2wfH+eS0XggJ0WS3dIST6YZSXZMlqtHCRYjCTCQ+SLpsyRiU6fLX9eZM+eordfjl2qvw2U0HjkW1I4Lzku/v8JtQZLQSHpjMmsU9TY2lpYAi0Cy1Z1diEyQswuRCXJ2ITJBzi5EJsjZhciEVXfjzawN4PsAxobP/wt3/5SZ3QzgKwCuB/AjAB91d74tisHuYofsnJY1vg3Oyi71uny4VpvnEVtYWKK2WrDDXFXpHdxul+/C9vt8rCigJbKxclgAULP0/KNSU9FYZZQLL9gFL4lUYhYoIcFu9rlTJ6ktUicc6Rx69SDIJKLT5UEyRcV3wutB7rr10CWBPFGuu7W84i6A97v72zAoz3yXmb0bwJ8C+Ly7/waASwA+dqUTFkKMjlWd3Qe8kr6zOfznAN4P4C+G7Q8B+OCWzFAIsSmstT57fVjB9RyA7wH4GYBZ93/Mk3wSwP6tmaIQYjNYk7O7e+nutwO4CcAdAN601gHM7KiZzZjZTL8f1KAVQmwpV7RL4e6zAP4GwG8BmDazV3YdbgJwivQ55u5H3P1IlCFGCLG1rOrsZrbbzKaHj8cB/B6AZzFw+n81fNq9AL69VZMUQmyctegB+wA8ZGZ1DN4cvubu/9fMngHwFTP7zwD+AcADaxnQyPtL8Jt/FCRvWRHIDB6UhorktUYgyfSJRBUFH5T99QVHRPJanIMuTfSpqggkr5rx9ajV+OVTr6dt7TafR5R3r9fl53qJBFcBQEUkwCiXXESYZ45IswAQqHKoE2k5WvuiuPKvxKs6u7s/AeDtifYXMfj+LoT4FUC/oBMiE+TsQmSCnF2ITJCzC5EJcnYhMsGiiKFNH8zsPIBfDP/cBeDCyAbnaB6vRvN4Nb9q8zjo7rtThpE6+6sGNptx9yPbMrjmoXlkOA99jBciE+TsQmTCdjr7sW0c+3I0j1ejebyaX5t5bNt3diHEaNHHeCEyYVuc3czuMrPnzOwFM7tvO+YwnMdxM3vSzB43s5kRjvugmZ0zs6cua9tpZt8zs58O/79um+bxaTM7NVyTx83sAyOYxwEz+xsze8bMnjazfzdsH+maBPMY6ZqYWdvM/t7Mfjycx38att9sZo8O/earZnZloXvuPtJ/AOoYpLV6PYAWgB8DuHXU8xjO5TiAXdsw7nsBvAPAU5e1/RcA9w0f3wfgT7dpHp8G8O9HvB77ALxj+HgHgOcB3DrqNQnmMdI1waAQ3dTwcRPAowDeDeBrAD48bP+fAP7tlRx3O+7sdwB4wd1f9EHq6a8AuHsb5rFtuPv3AVx8TfPdGCTuBEaUwJPMY+S4+2l3f2z4eAGD5Cj7MeI1CeYxUnzApid53Q5n3w/gxGV/b2eySgfwV2b2IzM7uk1zeIU97n56+PgMgD3bOJePm9kTw4/5W/514nLM7BAG+RMexTauyWvmAYx4TbYiyWvuG3R3uvs7APwLAH9sZu/d7gkBg3d2xIlstpIvArgFgxoBpwF8dlQDm9kUgG8A+IS7z19uG+WaJOYx8jXxDSR5ZWyHs58CcOCyv2myyq3G3U8N/z8H4FvY3sw7Z81sHwAM/+fFyrcQdz87vNAqAPdjRGtiZk0MHOxL7v7NYfPI1yQ1j+1ak+HYV5zklbEdzv5DAIeHO4stAB8G8PCoJ2Fmk2a245XHAH4fwFNxry3lYQwSdwLbmMDzFeca8iGMYE1skHDvAQDPuvvnLjONdE3YPEa9JluW5HVUO4yv2W38AAY7nT8D8B+2aQ6vx0AJ+DGAp0c5DwBfxuDjYB+D714fw6Bm3iMAfgrgrwHs3KZ5/G8ATwJ4AgNn2zeCedyJwUf0JwA8Pvz3gVGvSTCPka4JgLdikMT1CQzeWP7jZdfs3wN4AcDXAYxdyXH1CzohMiH3DTohskHOLkQmyNmFyAQ5uxCZIGcXIhPk7EJkgpxdiEyQswuRCf8fSqJ4Lg9O374AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[2000, :, :])\n",
    "plt.show();\n",
    "\n",
    "print(y_train[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.float()\n",
    "X_test = X_test.float()\n",
    "\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "X_train = X_train.permute(0, 3, 1, 2)\n",
    "X_test = X_test.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([50000, 3072])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = X_train.reshape([-1, 32*32*3])\n",
    "X_test = X_test.reshape([-1, 32*32*3])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 12 14:48:52 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  On   | 00000000:26:00.0 Off |                  N/A |\n",
      "| 41%   37C    P5    11W / 120W |    434MiB /  6075MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1088      G   /usr/lib/xorg/Xorg                            18MiB |\n",
      "|    0      1161      G   /usr/bin/gnome-shell                          47MiB |\n",
      "|    0      2524      G   /usr/lib/xorg/Xorg                           127MiB |\n",
      "|    0      2657      G   /usr/bin/gnome-shell                         114MiB |\n",
      "|    0      3037      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files   120MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFARNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(32*32*3, 2000)\n",
    "        self.do1 = torch.nn.Dropout(0.4)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(2000)\n",
    "        self.ac1 = torch.nn.ReLU()\n",
    "        \n",
    "        # self.fc2 = torch.nn.Linear(5000, 1000)\n",
    "        # self.do2 = torch.nn.Dropout(0.4)\n",
    "        # self.bn2 = torch.nn.BatchNorm1d(1000)\n",
    "        # self.ac2 = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(2000, 100)\n",
    "        self.do3 = torch.nn.Dropout(0.2)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(100)\n",
    "        self.ac3 = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc4 = torch.nn.Linear(100, 10)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.ac1(x)\n",
    "        \n",
    "        # x = self.fc2(x)\n",
    "        # x = self.do2(x)\n",
    "        # x = self.bn2(x)\n",
    "        # x = self.ac2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.do3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.ac3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "cifar_net = CIFARNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cifar_net.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cifar_net = cifar_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.1869, device='cuda:0')\n",
      "1 tensor(0.1838, device='cuda:0')\n",
      "2 tensor(0.1939, device='cuda:0')\n",
      "3 tensor(0.1905, device='cuda:0')\n",
      "4 tensor(0.1852, device='cuda:0')\n",
      "5 tensor(0.1845, device='cuda:0')\n",
      "6 tensor(0.1782, device='cuda:0')\n",
      "7 tensor(0.1711, device='cuda:0')\n",
      "8 tensor(0.1733, device='cuda:0')\n",
      "9 tensor(0.1750, device='cuda:0')\n",
      "10 tensor(0.1767, device='cuda:0')\n",
      "11 tensor(0.1755, device='cuda:0')\n",
      "12 tensor(0.1882, device='cuda:0')\n",
      "13 tensor(0.1724, device='cuda:0')\n",
      "14 tensor(0.1819, device='cuda:0')\n",
      "15 tensor(0.1696, device='cuda:0')\n",
      "16 tensor(0.1686, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 5.93 GiB total capacity; 4.72 GiB already allocated; 36.75 MiB free; 4.85 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-388480f32de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtest_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6bcf8743e985>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mac1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# x = self.fc2(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/labs/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/labs/venv/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/labs/venv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 5.93 GiB total capacity; 4.72 GiB already allocated; 36.75 MiB free; 4.85 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "test_accuracy_history = []\n",
    "test_loss_history = []\n",
    "validation_loss_history = []\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(100):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    \n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "\n",
    "        X_batch = X_train[batch_indexes].to(device)\n",
    "        y_batch = y_train[batch_indexes].to(device)\n",
    "\n",
    "        preds = cifar_net.forward(X_batch)\n",
    "\n",
    "        loss_value = loss(preds, y_batch)\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_preds = cifar_net.forward(X_test)\n",
    "    test_loss_history.append(loss(test_preds, y_test))\n",
    "    \n",
    "    validation_loss_history.append(loss_value)\n",
    "    \n",
    "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean()\n",
    "    test_accuracy_history.append(accuracy)\n",
    "    print(epoch, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
